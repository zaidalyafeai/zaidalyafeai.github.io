---
layout: archive
title: ""
permalink: /resume/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Full resume can be found  <a href="/files/resume.pdf" target="_blank">here</a>.

Education
======
* B.S. in Computer Science & Mathematics, KFUPM, 2016
* M.S. in Computer Science, KFUPM, 2019
* Ph.D in Computer Science, KFUPM, 2023 (expected)

Teaching Experience
======
* Spring 2022: Research Assistant
  * Instructor ICS 104 on Python
* Summer 2021, 2022 & 2023:
  * Teaching Assistant Summer school on Data Science
    
Leadership
======
* Leading [ARBML](https://arbml.github.io/website/) an open source initiative for Arabic NLP. Our [discord](https://discord.gg/aN2vaec9nV) contains +500 members. 
* Founding Member of [fihm.ai](https://fihm.ai/). An initiative to release Arabic AI resources.
* Organized [Birds-of-Feather: Low Resource NLP](https://docs.google.com/presentation/d/1LoXy0bjKc5XZejERGKHhH5OTeC-c2BiJ1gAXlQLGGXw/edit?usp=sharing) at Colling 2020. 
 
Open Source 
======

* Cofounder of [ARBML](https://arbml.github.io/website/) for democratizing Arabic NLP by revising the NLP pipeline for Arabic. We have many tools for preprocessing, tokenization, training and deployment. Our community on discord has +500 members.
* [AttentionNN](https://github.com/zaidalyafeai/AttentioNN) Implementations of attention in many models like transformers and GPT. 
* Enriching Arabic content with two datasets: [MetRec](https://github.com/ARBML/MetRec) and [Calliar](https://github.com/ARBML/Calliar). 
* Creator of [klaam](https://github.com/ARBML/klaam) and [whisperar](https://github.com/ARBML/whisperar), Arabic speech recognition and text-to-speech libraries. 
* Designed many easy to use [creative applications](https://github.com/zaidalyafeai/ml-projects) for deep learning.
* Founding member of [fihm.ai](https://fihm.ai/), where we publish Arabic articles on AI. 

Collaborations and sprints  
======
* [C4AI](https://cohere.for.ai/) member working on the Aya project for multilignual instruction tuning 2023-now. 
* HuggingFace whisper finetuning Dec 2022. 
* [BigScience](https://bigscience.huggingface.co/) member with focus on tokenization, data sourcing and prompt engineering 2021-2022. 
* HuggingFace XLSR-Wav2Vec2 Fine-Tuning Week for Low-Resource Languages 22-29 Mar 2021.
* HuggingFace datasets sprint 1-13 Dec 2020.  
* Collaborated with researchers from Aramco for ESP failure prediction using different techniques of machine learning 2019-2021. 
* I worked on distributed training of GPT-2 on 4 GPUs for Arabic poetry generation in collaboration with Kyle McDonald 2019-2020. 
* Collaborated with researchers from CPG at KFUPM for modelling sand dunes 2019-2020. 

Competitions 
======
* Fourth in the [Barmjan](https://arabicthon.ksaa.gov.sa/) compeition, where we created an app for poetry analysis called [Qawafi](https://github.com/ARBML/qawafi), 2022. 
* Second in the Ai in sport [challenge](https://thakaa.sa/challenges/sports-challenge?utm_source=thakaa&utm_campaign=%D8%AA%D8%AD%D8%AF%D9%8A+%D8%A7%D9%84%D8%B0%D9%83%D8%A7%D8%A1+%D8%A7%D9%84%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%D9%8A+%D9%81%D9%8A+%D8%A7%D9%84%D8%B1%D9%8A%D8%A7%D8%B6%D8%A9) with our solution [Ain sports](https://ainsports.github.io/), 2022. 
* First in the integration contest at KFUPM, 2013. 

Articles and Books
======
* Article: [A Gentle Introduction to TensorFlow.js](https://blog.tensorflow.org/2018/04/a-gentle-introduction-to-tensorflowjs.html).
* Article: [Train a model in tf.keras with Colab, and run it in the browser with TensorFlow.js](https://medium.com/tensorflow/train-on-google-colab-and-run-on-the-browser-a-case-study-8a45f9b1474e)
* Article: [A dive into the Latent Space of BigGan](https://thegradient.pub/bigganex-a-dive-into-the-latent-space-of-biggan/).
* Book: [Advanced Integration Techniques](/files/book.pdf).
* Book Chapter: [Practical Deep Learning for Cloud Mobile & Edge](https://www.amazon.com/Practical-Learning-Cloud-Mobile-Hands/dp/149203486X) .

Skills
======
* Python, Pytorch & TensorFlow
* Multi-GPU Training & Inference
* TPU Training 

Talks
======
  <ul>{% for post in site.talks %}
    {% include archive-single-talk-cv.html %}
  {% endfor %}</ul>

Publications
======
  Check the publications <a href="/publications/" target="_blank">pages</a>.